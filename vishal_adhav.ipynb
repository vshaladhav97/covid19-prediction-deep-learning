{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OklpTviQiQKY",
        "outputId": "9df8ef3c-8062-47d5-f16a-d4fdc71035d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/covid.train.csv')\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB6j9ebgsreY",
        "outputId": "6f377f11-45a1-4f06-bc4d-e4d4217e7263"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'FL', 'GA', 'ID', 'IL',\n",
            "       'IN', 'IA', 'KS', 'KY', 'LA', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'NE',\n",
            "       'NV', 'NJ', 'NM', 'NY', 'NC', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'TX',\n",
            "       'UT', 'VA', 'WA', 'WV', 'WI', 'cli', 'ili', 'hh_cmnty_cli',\n",
            "       'nohh_cmnty_cli', 'wearing_mask', 'travel_outside_state',\n",
            "       'work_outside_home', 'shop', 'restaurant', 'spent_time', 'large_event',\n",
            "       'public_transit', 'anxious', 'depressed', 'felt_isolated',\n",
            "       'worried_become_ill', 'worried_finances', 'tested_positive', 'cli.1',\n",
            "       'ili.1', 'hh_cmnty_cli.1', 'nohh_cmnty_cli.1', 'wearing_mask.1',\n",
            "       'travel_outside_state.1', 'work_outside_home.1', 'shop.1',\n",
            "       'restaurant.1', 'spent_time.1', 'large_event.1', 'public_transit.1',\n",
            "       'anxious.1', 'depressed.1', 'felt_isolated.1', 'worried_become_ill.1',\n",
            "       'worried_finances.1', 'tested_positive.1', 'cli.2', 'ili.2',\n",
            "       'hh_cmnty_cli.2', 'nohh_cmnty_cli.2', 'wearing_mask.2',\n",
            "       'travel_outside_state.2', 'work_outside_home.2', 'shop.2',\n",
            "       'restaurant.2', 'spent_time.2', 'large_event.2', 'public_transit.2',\n",
            "       'anxious.2', 'depressed.2', 'felt_isolated.2', 'worried_become_ill.2',\n",
            "       'worried_finances.2', 'tested_positive.2'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/covid.test.csv')\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqCzT-jKswCg",
        "outputId": "5130971b-7aec-4514-86a0-2ca0d64e0105"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'FL', 'GA', 'ID', 'IL',\n",
            "       'IN', 'IA', 'KS', 'KY', 'LA', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'NE',\n",
            "       'NV', 'NJ', 'NM', 'NY', 'NC', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'TX',\n",
            "       'UT', 'VA', 'WA', 'WV', 'WI', 'cli', 'ili', 'hh_cmnty_cli',\n",
            "       'nohh_cmnty_cli', 'wearing_mask', 'travel_outside_state',\n",
            "       'work_outside_home', 'shop', 'restaurant', 'spent_time', 'large_event',\n",
            "       'public_transit', 'anxious', 'depressed', 'felt_isolated',\n",
            "       'worried_become_ill', 'worried_finances', 'tested_positive', 'cli.1',\n",
            "       'ili.1', 'hh_cmnty_cli.1', 'nohh_cmnty_cli.1', 'wearing_mask.1',\n",
            "       'travel_outside_state.1', 'work_outside_home.1', 'shop.1',\n",
            "       'restaurant.1', 'spent_time.1', 'large_event.1', 'public_transit.1',\n",
            "       'anxious.1', 'depressed.1', 'felt_isolated.1', 'worried_become_ill.1',\n",
            "       'worried_finances.1', 'tested_positive.1', 'cli.2', 'ili.2',\n",
            "       'hh_cmnty_cli.2', 'nohh_cmnty_cli.2', 'wearing_mask.2',\n",
            "       'travel_outside_state.2', 'work_outside_home.2', 'shop.2',\n",
            "       'restaurant.2', 'spent_time.2', 'large_event.2', 'public_transit.2',\n",
            "       'anxious.2', 'depressed.2', 'felt_isolated.2', 'worried_become_ill.2',\n",
            "       'worried_finances.2'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_and_preprocess_data(filepath, target_column=None, scaler=None):\n",
        "    # Load data\n",
        "    df = pd.read_csv(filepath)\n",
        "\n",
        "    # Drop the 'id' column\n",
        "    df = df.drop(columns=['id'])\n",
        "\n",
        "    if target_column is not None:\n",
        "        # Separate features and target for training data\n",
        "        X = df.drop(columns=[target_column])\n",
        "        y = df[target_column]\n",
        "    else:\n",
        "        # For test data, just return the features\n",
        "        X = df\n",
        "        y = None\n",
        "\n",
        "    # Normalize features\n",
        "    if scaler is None:\n",
        "        scaler = StandardScaler()\n",
        "        X = scaler.fit_transform(X)\n",
        "    else:\n",
        "        X = scaler.transform(X)\n",
        "\n",
        "    return X, y, scaler\n",
        "\n"
      ],
      "metadata": {
        "id": "vp7XGZ8olZMM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network\n",
        "class CovidPredictionModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(CovidPredictionModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.fc4 = nn.Linear(32, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "etlSwobLnMLB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "def train_model(model, X_train, y_train, criterion, optimizer, num_epochs=1000):\n",
        "    model.train()\n",
        "    X_train = torch.FloatTensor(X_train)\n",
        "    y_train = torch.FloatTensor(y_train.values).view(-1, 1)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_train)\n",
        "        loss = criterion(outputs, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (epoch+1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_val, y_val, criterion):\n",
        "    model.eval()\n",
        "    X_val = torch.FloatTensor(X_val)\n",
        "    y_val = torch.FloatTensor(y_val.values).view(-1, 1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X_val)\n",
        "        loss = criterion(outputs, y_val)\n",
        "\n",
        "    return loss.item()\n",
        "\n"
      ],
      "metadata": {
        "id": "LPs2tvVOnTfb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Define the target column\n",
        "    target_column = 'tested_positive.2'\n",
        "\n",
        "    # Load and preprocess training data\n",
        "    X, y, scaler = load_and_preprocess_data('/content/drive/MyDrive/covid.train.csv', target_column=target_column)\n",
        "\n",
        "    # Split data into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize model, criterion, and optimizer\n",
        "    input_dim = X_train.shape[1]\n",
        "    model = CovidPredictionModel(input_dim)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Train the model\n",
        "    train_model(model, X_train, y_train, criterion, optimizer, num_epochs=1000)\n",
        "\n",
        "    # Evaluate the model\n",
        "    val_loss = evaluate_model(model, X_val, y_val, criterion)\n",
        "    print(f'Validation Loss: {val_loss:.4f}')\n",
        "\n",
        "    # Load and preprocess test data (no target column here)\n",
        "    X_test, _, _ = load_and_preprocess_data('/content/drive/MyDrive/covid.test.csv', scaler=scaler)\n",
        "\n",
        "    # Make predictions\n",
        "    model.eval()\n",
        "    X_test = torch.FloatTensor(X_test)\n",
        "    with torch.no_grad():\n",
        "        predictions = model(X_test)\n",
        "\n",
        "    # Save predictions to a file\n",
        "    np.savetxt('/content/drive/MyDrive/predictions.csv', predictions.numpy(), delimiter=',')\n",
        "    print(\"Predictions saved to 'predictions.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If_PooDXnXgj",
        "outputId": "9baf0a96-8af7-45f9-ef86-08055e94261e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 15.1926\n",
            "Epoch [200/1000], Loss: 11.0573\n",
            "Epoch [300/1000], Loss: 9.6359\n",
            "Epoch [400/1000], Loss: 9.5095\n",
            "Epoch [500/1000], Loss: 9.1399\n",
            "Epoch [600/1000], Loss: 9.0148\n",
            "Epoch [700/1000], Loss: 8.2545\n",
            "Epoch [800/1000], Loss: 8.5634\n",
            "Epoch [900/1000], Loss: 8.3076\n",
            "Epoch [1000/1000], Loss: 8.5280\n",
            "Validation Loss: 1.1615\n",
            "Predictions saved to 'predictions.csv'\n"
          ]
        }
      ]
    }
  ]
}